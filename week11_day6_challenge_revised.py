# -*- coding: utf-8 -*-
"""Week11/day6/challenge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XLYMcsE5Eju-7qkVFYXG5SOOPewwFRy9
"""

import zipfile
import os

# List the contents of the ZIP file
with zipfile.ZipFile('/content/Airplane_crashes.zip', 'r') as zip_ref:
    print(zip_ref.namelist())

df = pd.read_csv('/content/Airplane_Crashes_and_Fatalities_Since_1908_t0_2023.csv', encoding='latin-1')

# Print column names
print("Column names:")
print(df.columns.tolist())

# Print data types of each column
print("\nData types:")
print(df.dtypes)

# Print basic information about the dataset
print("\nDataset info:")
df.info()

# Print the first few rows of the dataset
print("\nFirst few rows:")
print(df.head().to_string())

import pandas as pd
import numpy as np

# Read the CSV file
df = pd.read_csv('/content/Airplane_Crashes_and_Fatalities_Since_1908_t0_2023.csv', encoding='latin-1')

def clean_data(df):
    # Combine 'Date' and 'Time' columns into 'DateTime'
    df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'], errors='coerce')

    # Drop original 'Date' and 'Time' columns
    df.drop(['Date', 'Time'], axis=1, inplace=True)

    # Fill NaN values in string columns
    string_columns = ['Location', 'Operator', 'Flight #', 'Route', 'AC Type', 'Registration', 'cn/ln', 'Summary']
    for col in string_columns:
        df[col].fillna('Unknown', inplace=True)

    # Convert numeric columns to appropriate types and fill NaN values with 0
    numeric_columns = ['Aboard', 'Aboard Passangers', 'Aboard Crew', 'Fatalities',
                       'Fatalities Passangers', 'Fatalities Crew', 'Ground']
    for col in numeric_columns:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    # Remove any remaining rows with NaN values in DateTime
    df.dropna(subset=['DateTime'], inplace=True)

    # Sort the dataframe by DateTime
    df.sort_values('DateTime', inplace=True)

    return df

# Clean the data
cleaned_df = clean_data(df)

# Display info about the cleaned dataset
print(cleaned_df.info())

# Display the first few rows of the cleaned dataset
print(cleaned_df.head().to_string())

# Save the cleaned dataset
cleaned_df.to_csv('cleaned_airplane_crashes.csv', index=False)

# Print some basic statistics
print("\nBasic Statistics:")
print(cleaned_df[['Aboard', 'Fatalities', 'Ground']].describe())

# Print the number of crashes per year
print("\nNumber of crashes per year:")
print(cleaned_df['DateTime'].dt.year.value_counts().sort_index())

# Print the top 10 locations with the most crashes
print("\nTop 10 locations with the most crashes:")
print(cleaned_df['Location'].value_counts().head(10))

# Print the top 10 operators with the most crashes
print("\nTop 10 operators with the most crashes:")
print(cleaned_df['Operator'].value_counts().head(10))

import pandas as pd
import matplotlib.pyplot as plt

# Read the cleaned CSV file
df = pd.read_csv('cleaned_airplane_crashes.csv')

# Convert DateTime to datetime type
df['DateTime'] = pd.to_datetime(df['DateTime'])

# Count crashes per year
crashes_per_year = df['DateTime'].dt.year.value_counts().sort_index()

# Create the plot
plt.figure(figsize=(15, 8))
crashes_per_year.plot(kind='bar')

plt.title('Number of Airplane Crashes per Year', fontsize=16)
plt.xlabel('Year', fontsize=12)
plt.ylabel('Number of Crashes', fontsize=12)
plt.xticks(rotation=45, ha='right')

# Improve the x-axis labels (show every 5th year)
plt.gca().xaxis.set_major_locator(plt.MultipleLocator(5))

plt.tight_layout()

# Save the plot
plt.savefig('crashes_per_year.png')

# Display the plot
plt.show()

# Print some statistics
print(f"Total number of years: {len(crashes_per_year)}")
print(f"Year with most crashes: {crashes_per_year.idxmax()} ({crashes_per_year.max()} crashes)")
print(f"Year with least crashes: {crashes_per_year.idxmin()} ({crashes_per_year.min()} crashes)")
print(f"Average crashes per year: {crashes_per_year.mean():.2f}")

import pandas as pd
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# Read the cleaned CSV file
df = pd.read_csv('cleaned_airplane_crashes.csv')

# Convert DateTime to datetime type
df['DateTime'] = pd.to_datetime(df['DateTime'])

# 1. Analyze the distribution of fatalities and survival rates

# Calculate survival rate
df['Survival_Rate'] = 1 - (df['Fatalities'] / df['Aboard'])

# Calculate key statistics
fatalities_mean = df['Fatalities'].mean()
fatalities_median = df['Fatalities'].median()
fatalities_std = df['Fatalities'].std()
survival_rate_mean = df['Survival_Rate'].mean()
survival_rate_median = df['Survival_Rate'].median()
survival_rate_std = df['Survival_Rate'].std()

print("Fatalities Statistics:")
print(f"Mean: {fatalities_mean:.2f}")
print(f"Median: {fatalities_median:.2f}")
print(f"Standard Deviation: {fatalities_std:.2f}")

print("\nSurvival Rate Statistics:")
print(f"Mean: {survival_rate_mean:.2f}")
print(f"Median: {survival_rate_median:.2f}")
print(f"Standard Deviation: {survival_rate_std:.2f}")

# Visualize the distribution of fatalities
plt.figure(figsize=(10, 6))
plt.hist(df['Fatalities'], bins=50, edgecolor='black')
plt.title('Distribution of Fatalities')
plt.xlabel('Number of Fatalities')
plt.ylabel('Frequency')
plt.show()

# 2. Conduct a hypothesis test

# Let's compare the average number of fatalities in two different decades: 1990s vs 2000s

df['Decade'] = df['DateTime'].dt.year // 10 * 10

fatalities_1990s = df[df['Decade'] == 1990]['Fatalities']
fatalities_2000s = df[df['Decade'] == 2000]['Fatalities']

# Perform independent t-test
t_statistic, p_value = stats.ttest_ind(fatalities_1990s, fatalities_2000s)

print("\nHypothesis Test: Comparing average fatalities in 1990s vs 2000s")
print(f"T-statistic: {t_statistic:.4f}")
print(f"P-value: {p_value:.4f}")

# Interpret the results
alpha = 0.05  # Significance level
if p_value < alpha:
    print("The difference in average fatalities between the 1990s and 2000s is statistically significant.")
    print("We reject the null hypothesis that the average fatalities are the same for these two decades.")
else:
    print("The difference in average fatalities between the 1990s and 2000s is not statistically significant.")
    print("We fail to reject the null hypothesis that the average fatalities are the same for these two decades.")

# Print mean fatalities for each decade
print(f"\nMean fatalities in 1990s: {fatalities_1990s.mean():.2f}")
print(f"Mean fatalities in 2000s: {fatalities_2000s.mean():.2f}")

# Visualize the comparison
plt.figure(figsize=(10, 6))
plt.boxplot([fatalities_1990s, fatalities_2000s], labels=['1990s', '2000s'])
plt.title('Fatalities: 1990s vs 2000s')
plt.ylabel('Number of Fatalities')
plt.show()

"""Lets analyse a flight safety trend over the time beginning from 1940, assuming that before 1940 the ammount of flights was not sufficient enough. I suggest to use a Survival Rate as an andicator becouse the higher the survival rate, the less serious problems the aircrafts faced. As a Survival Rate for this purpose i used a share of survived from the whole ammount of the participants of the crashes"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score

df = pd.read_csv('cleaned_airplane_crashes.csv')

# Convert DateTime to datetime type and extract year
df['DateTime'] = pd.to_datetime(df['DateTime'])
df['Year'] = df['DateTime'].dt.year

# Filter data from 1940 to 2020
df_filtered = df[(df['Year'] >= 1940) & (df['Year'] <= 2020)]

# Calculate survival rate for each year
yearly_survival = df_filtered.groupby('Year').agg({
    'Aboard': 'sum',
    'Fatalities Passangers': 'sum',
    'Fatalities Crew': 'sum'
}).reset_index()

yearly_survival['Survival_Rate'] = (yearly_survival['Aboard'] -
                                    (yearly_survival['Fatalities Passangers'] + yearly_survival['Fatalities Crew'])) / yearly_survival['Aboard']

# Prepare data for polynomial regression
X = yearly_survival['Year'].values.reshape(-1, 1)
y = yearly_survival['Survival_Rate'].values

# Create polynomial features (degree 3 for a cubic trend)
poly = PolynomialFeatures(degree=3)
X_poly = poly.fit_transform(X)

# Fit polynomial regression
model = LinearRegression()
model.fit(X_poly, y)

# Generate points for smooth curve
X_smooth = np.linspace(1940, 2020, 500).reshape(-1, 1)
X_smooth_poly = poly.transform(X_smooth)
y_smooth = model.predict(X_smooth_poly)

# Calculate R-squared
r2 = r2_score(y, model.predict(X_poly))

# Create the plot
plt.figure(figsize=(15, 8))
plt.scatter(yearly_survival['Year'], yearly_survival['Survival_Rate'], color='blue', alpha=0.6, label='Actual data')
plt.plot(X_smooth, y_smooth, color='red', label='Polynomial trend')
plt.title('Airplane Crash Survival Rate (1940-2020) with Non-linear Trend', fontsize=16)
plt.xlabel('Year', fontsize=12)
plt.ylabel('Survival Rate', fontsize=12)
plt.ylim(0, 1)
plt.yticks([i/10 for i in range(11)])
plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend()
plt.text(1940, 0.05, f'RÂ² = {r2:.4f}', fontsize=10)
plt.tight_layout()
plt.savefig('survival_rate_nonlinear_trend_1940_2020_updated.png')
plt.show()

# Extract trend information
trend_1940 = model.predict(poly.transform([[1940]]))[0]
trend_2020 = model.predict(poly.transform([[2020]]))[0]
trend_max = np.max(y_smooth)
trend_max_year = X_smooth[np.argmax(y_smooth)][0]

print("Trend Information:")
print(f"Trend magnitude in 1940: {trend_1940:.2%}")
print(f"Trend magnitude in 2020: {trend_2020:.2%}")
print(f"Maximum trend value: {trend_max:.2%}")
print(f"Year of maximum trend value: {trend_max_year:.0f}")

"""If we consider the Survival Rate as an indicator of flight safety, then from 1940 to 2000, flight safety increased. Starting in 2000, it began to decline, but by 2020, it was still higher than in 1940."""