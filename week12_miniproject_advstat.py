# -*- coding: utf-8 -*-
"""Week12/miniproject/advstat.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B_fnTjQ2ajfD-HbagcLHoKQeVa65tzBu
"""

!wget https://raw.githubusercontent.com/devtlv/MiniProject-DataAnalysis-W6D5-Apple_Stock_Data/main/AAPL%2C%201D%2001012007-12072023.csv

"""**Initial Data Exploration**"""

import pandas as pd

df = pd.read_csv('/content/AAPL, 1D 01012007-12072023.csv')

print(df.isnull().sum())

print(df.dtypes)

print(df.head())

# Convert the 'time' column to datetime
df['datetime'] = pd.to_datetime(df['time'], unit='s')

# Set the 'datetime' column as the index
df.set_index('datetime', inplace=True)

# Drop the original 'time' column
df.drop('time', axis=1, inplace=True)

print(df.head())

# Display updated data types
print("\nUpdated Data Types:")
print(df.dtypes)

import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose
import seaborn as sns

# Read the CSV file and set the index
df = pd.read_csv('/content/AAPL, 1D 01012007-12072023.csv')
df['datetime'] = pd.to_datetime(df['time'], unit='s')
df.set_index('datetime', inplace=True)
df.drop('time', axis=1, inplace=True)

# 1. Examine data frequency
print("1. Data Frequency:")
print(df.index.freq)
print(f"Time range: {df.index.min()} to {df.index.max()}")
print(f"Number of observations: {len(df)}")
print(f"Average time delta: {df.index.to_series().diff().mean()}")

# 2. Check for missing dates
all_dates = pd.date_range(start=df.index.min(), end=df.index.max(), freq='D')
missing_dates = all_dates.difference(df.index)
print(f"\n2. Number of missing dates: {len(missing_dates)}")

# 3. Basic statistical properties
print("\n3. Basic Statistical Properties:")
print(df['close'].describe())

# 4. Trend analysis
plt.figure(figsize=(15, 7))
plt.plot(df.index, df['close'])
plt.title('AAPL Stock Closing Price Over Time')
plt.xlabel('Date')
plt.ylabel('Closing Price')
plt.show()

# 5. Seasonal Decomposition
decomposition = seasonal_decompose(df['close'], model='additive', period=252)  # 252 trading days in a year

fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(15, 20))
decomposition.observed.plot(ax=ax1)
ax1.set_title('Observed')
decomposition.trend.plot(ax=ax2)
ax2.set_title('Trend')
decomposition.seasonal.plot(ax=ax3)
ax3.set_title('Seasonal')
decomposition.resid.plot(ax=ax4)
ax4.set_title('Residual')
plt.tight_layout()
plt.show()

# 6. Distribution of returns
df['returns'] = df['close'].pct_change()
plt.figure(figsize=(15, 7))
sns.histplot(df['returns'].dropna(), kde=True)
plt.title('Distribution of Daily Returns')
plt.xlabel('Daily Return')
plt.show()

# 7. Volatility
df['volatility'] = df['returns'].rolling(window=252).std() * (252**0.5)
plt.figure(figsize=(15, 7))
plt.plot(df.index, df['volatility'])
plt.title('252-day Rolling Volatility')
plt.xlabel('Date')
plt.ylabel('Volatility')
plt.show()

"""**Data Visualization**"""

!pip install mplfinance

import pandas as pd
import mplfinance as mpf

df = pd.read_csv('/content/AAPL, 1D 01012007-12072023.csv')
df['datetime'] = pd.to_datetime(df['time'], unit='s')
df.set_index('datetime', inplace=True)

# Prepare data for mplfinance
df_mpf = df[['open', 'high', 'low', 'close', 'volume']].copy()

# Plot the last 2 years of data
df_mpf = df_mpf.last('730D')

# Create the candlestick chart
mpf.plot(df_mpf, type='candle', style='yahoo', volume=True,
         title='AAPL Candlestick Chart (Last 2 Years)',
         figsize=(20, 12), mav=(20, 50, 200))

"""**Statistical Analysis**"""

import pandas as pd
import matplotlib.pyplot as plt


df = pd.read_csv('/content/AAPL, 1D 01012007-12072023.csv')
df['datetime'] = pd.to_datetime(df['time'], unit='s')
df.set_index('datetime', inplace=True)

# 1. Compute summary statistics
columns_to_analyze = ['volume', 'vwap', 'open', 'close', 'high', 'low']
summary_stats = df[columns_to_analyze].describe()

print("Summary Statistics:")
print(summary_stats)

# 2. Analyze closing prices with moving averages
# Calculate 50-day and 200-day moving averages
df['MA50'] = df['close'].rolling(window=50).mean()
df['MA200'] = df['close'].rolling(window=200).mean()

# Plot closing prices and moving averages
plt.figure(figsize=(15, 10))
plt.plot(df.index, df['close'], label='Closing Price', alpha=0.5)
plt.plot(df.index, df['MA50'], label='50-day MA', linewidth=2)
plt.plot(df.index, df['MA200'], label='200-day MA', linewidth=2)
plt.title('AAPL Closing Prices with Moving Averages')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.grid(True)
plt.show()

"""**Hypothesis Testing**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import seaborn as sns

# Read the CSV file
df = pd.read_csv('/content/AAPL, 1D 01012007-12072023.csv')
df['datetime'] = pd.to_datetime(df['time'], unit='s')
df.set_index('datetime', inplace=True)

# 1. T-test to compare average closing prices across different years
df['year'] = df.index.year
yearly_avg_close = df.groupby('year')['close'].mean()

print("Yearly Average Closing Prices:")
print(yearly_avg_close)

# Perform t-test between consecutive years
years = sorted(df['year'].unique())
for i in range(len(years) - 1):
    year1 = years[i]
    year2 = years[i + 1]
    t_stat, p_value = stats.ttest_ind(df[df['year'] == year1]['close'],
                                      df[df['year'] == year2]['close'])
    print(f"\nT-test between {year1} and {year2}:")
    print(f"T-statistic: {t_stat:.4f}")
    print(f"P-value: {p_value:.4f}")

# 2. Examine daily returns' distribution and test for normality
df['daily_return'] = df['close'].pct_change()

# Plot histogram of daily returns
plt.figure(figsize=(12, 6))
sns.histplot(df['daily_return'].dropna(), kde=True, bins=100)
plt.title('Distribution of Daily Returns')
plt.xlabel('Daily Return')
plt.ylabel('Frequency')
plt.show()

# Q-Q plot
plt.figure(figsize=(12, 6))
stats.probplot(df['daily_return'].dropna(), dist="norm", plot=plt)
plt.title("Q-Q Plot of Daily Returns")
plt.show()

# Shapiro-Wilk test for normality
shapiro_test = stats.shapiro(df['daily_return'].dropna())
print("\nShapiro-Wilk Test for Normality of Daily Returns:")
print(f"Statistic: {shapiro_test.statistic:.4f}")
print(f"P-value: {shapiro_test.pvalue:.4f}")

# 3. Additional analysis: Skewness and Kurtosis
skewness = df['daily_return'].skew()
kurtosis = df['daily_return'].kurtosis()

print(f"\nSkewness of Daily Returns: {skewness:.4f}")
print(f"Kurtosis of Daily Returns: {kurtosis:.4f}")

"""The results suggest that AAPL stock has shown significant year-over-year growth, but its daily returns do not follow a normal distribution. The returns distribution has slightly heavier tails and more extreme events than a normal distribution would predict."""