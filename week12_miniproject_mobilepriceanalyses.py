# -*- coding: utf-8 -*-
"""Week12/miniproject/mobilepriceanalyses.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HGLHYkEf9bJG7AQt6SRrupLSqKs9dZZ-
"""

!wget https://raw.githubusercontent.com/devtlv/DailyChallenge-DataAnalysis-W6D5-Mobile_Price_Classification/main/train.csv

import pandas as pd

df = pd.read_csv('/content/train.csv')

# Check for null values
print(df.isnull().sum())

# Understand data types
print(df.dtypes)

# Display first few rows
print(df.head())

import pandas as pd
import numpy as np


df = pd.read_csv('/content/train.csv')

# Function to calculate mode (using pandas)
def calculate_mode(series):
    mode = series.mode()
    return list(mode) if len(mode) > 0 else None

# Function to perform detailed statistical analysis
def detailed_stats(column):
    return pd.Series({
        'Mean': column.mean(),
        'Median': column.median(),
        'Mode': calculate_mode(column),
        'Range': column.max() - column.min(),
        'Variance': column.var(),
        'Std Dev': column.std(),
        'Skewness': column.skew(),
        'Kurtosis': column.kurtosis()
    })

# Perform analysis on each numeric column
numeric_columns = df.select_dtypes(include=[np.number]).columns
results = df[numeric_columns].apply(detailed_stats)

# Display results
print(results.T)

# Additional information about distribution shapes
for column in numeric_columns:
    skewness = results.loc['Skewness', column]
    kurtosis = results.loc['Kurtosis', column]

    print(f"\nDistribution shape for {column}:")
    if abs(skewness) < 0.5:
        print("- Approximately symmetric")
    elif skewness < 0:
        print("- Negatively skewed (left-tailed)")
    else:
        print("- Positively skewed (right-tailed)")

    if abs(kurtosis) < 0.5:
        print("- Mesokurtic (normal kurtosis)")
    elif kurtosis < 0:
        print("- Platykurtic (flatter than normal)")
    else:
        print("- Leptokurtic (more peaked than normal)")

import pandas as pd
import numpy as np
from scipy import stats


df = pd.read_csv('/content/train.csv')

# Separate continuous and categorical variables
continuous_vars = ['battery_power', 'clock_speed', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']
categorical_vars = ['blue', 'dual_sim', 'fc', 'four_g', 'three_g', 'touch_screen', 'wifi']

def perform_anova(df, var):
    groups = [group for _, group in df.groupby('price_range')[var]]
    f_value, p_value = stats.f_oneway(*groups)
    return f_value, p_value

def perform_chi_square(df, var):
    contingency_table = pd.crosstab(df['price_range'], df[var])
    chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
    return chi2, p_value

print("ANOVA Test Results for Continuous Variables:")
for var in continuous_vars:
    f_value, p_value = perform_anova(df, var)
    print(f"{var}: F-value = {f_value:.4f}, p-value = {p_value:.4f}")

print("\nChi-Square Test Results for Categorical Variables:")
for var in categorical_vars:
    chi2, p_value = perform_chi_square(df, var)
    print(f"{var}: Chi-square = {chi2:.4f}, p-value = {p_value:.4f}")

# Post-hoc analysis for ANOVA (Tukey's HSD test)
from statsmodels.stats.multicomp import pairwise_tukeyhsd

print("\nTukey's HSD Test Results for Continuous Variables:")
for var in continuous_vars:
    tukey_results = pairwise_tukeyhsd(df[var], df['price_range'])
    print(f"\n{var}:")
    print(tukey_results)

# Effect size calculation for ANOVA (Eta-squared)
def calculate_eta_squared(df, var):
    groups = [group for _, group in df.groupby('price_range')[var]]
    f_value, _ = stats.f_oneway(*groups)
    eta_sq = (f_value * (len(groups) - 1)) / (f_value * (len(groups) - 1) + sum(len(g) for g in groups) - len(groups))
    return eta_sq

print("\nEffect Size (Eta-squared) for Continuous Variables:")
for var in continuous_vars:
    eta_sq = calculate_eta_squared(df, var)
    print(f"{var}: Eta-squared = {eta_sq:.4f}")

"""RAM is the most influential factor in determining phone price, with a very large effect size and significant differences across all price ranges.
Battery power, screen resolution (px_height and px_width), and to a lesser extent, internal memory and number of cores, also play significant roles in price determination.
Processor clock speed and primary camera megapixels don't show significant differences across price ranges.
For categorical features (e.g., Bluetooth, dual SIM, 4G), there's no significant association with price range, suggesting these are common across all price segments.
Physical attributes like mobile weight and thickness (m_dep) show little to no significant difference across price ranges.
Talk time doesn't significantly differ across price ranges, indicating it might not be a key factor in pricing.

**Conclusions:**

RAM is the primary differentiator for mobile phone pricing in this dataset.
Battery capacity and screen resolution are secondary factors in determining price.
Many features (e.g., Bluetooth, WiFi, touch screen) are likely standard across all price ranges.
Manufacturers might focus on RAM, battery, and display to justify higher prices, rather than on processing speed or camera quality.
"""

import pandas as pd
import numpy as np
from scipy import stats

# Load the data
df = pd.read_csv('/content/train.csv')

# Separate continuous and categorical variables
continuous_vars = ['battery_power', 'clock_speed', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']
categorical_vars = ['blue', 'dual_sim', 'fc', 'four_g', 'three_g', 'touch_screen', 'wifi']

# Function to calculate Pearson correlation
def pearson_correlation(x, y):
    return stats.pearsonr(x, y)

# Function to calculate point-biserial correlation
def point_biserial_correlation(x, y):
    return stats.pointbiserialr(x, y)

# Calculate correlations for continuous variables
print("Pearson Correlations for Continuous Variables:")
for var in continuous_vars:
    corr, p_value = pearson_correlation(df[var], df['price_range'])
    print(f"{var}: correlation = {corr:.4f}, p-value = {p_value:.4f}")

# Calculate correlations for categorical variables
print("\nPoint-Biserial Correlations for Categorical Variables:")
for var in categorical_vars:
    corr, p_value = point_biserial_correlation(df[var], df['price_range'])
    print(f"{var}: correlation = {corr:.4f}, p-value = {p_value:.4f}")

# Calculate Spearman rank correlation for all variables
print("\nSpearman Rank Correlations for All Variables:")
for var in continuous_vars + categorical_vars:
    corr, p_value = stats.spearmanr(df[var], df['price_range'])
    print(f"{var}: correlation = {corr:.4f}, p-value = {p_value:.4f}")

# Visualize correlations using a heatmap
import matplotlib.pyplot as plt
import seaborn as sns

# Calculate correlation matrix
corr_matrix = df[continuous_vars + categorical_vars + ['price_range']].corr(method='spearman')

# Create heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)
plt.title('Spearman Correlation Heatmap')
plt.tight_layout()
plt.show()

"""RAM: Shows the strongest correlation with price range across all correlation types. This confirms our earlier finding that RAM is the most crucial factor in determining phone price.
Battery Power: Demonstrates a moderate positive correlation indicating that higher-priced phones tend to have larger battery capacities.
Screen Resolution: Both pixel width and height show weak to moderate positive correlations with price, suggesting that higher-resolution screens are associated with higher-priced phones.
Internal Memory: Shows a very weak positive correlation, suggesting a slight tendency for higher-priced phones to have more internal storage.
Categorical Variables: None of the categorical variables (like Bluetooth, dual SIM, 4G) showed significant correlations with price range, confirming our earlier conclusion that these features are likely common across all price segments.
"""