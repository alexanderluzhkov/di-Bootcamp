# -*- coding: utf-8 -*-
"""Week7/day6/challenge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DVURqSu6geJNRJfm_J0_WNVmX1cjXcDL
"""

# Step 1: Upload and Set Up Kaggle API
from google.colab import files

# Upload kaggle.json
files.upload()

# Move it to the correct directory
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Step 2: Install and Authenticate Kaggle API
!pip install kaggle
from kaggle.api.kaggle_api_extended import KaggleApi

# Authenticate the API
api = KaggleApi()
api.authenticate()

# Step 3: Download the Iris Dataset
dataset = 'arshid/iris-flower-dataset'
api.dataset_download_files(dataset, path='.', unzip=True)

# Step 4: List the Files
!ls -lha

import pandas as pd

# Load the CSV file into a DataFrame
file_path = '/content/IRIS.csv'
df = pd.read_csv(file_path, header=None)  # Read without assuming headers

df.head()

# Display basic information about the DataFrame
df.info()

# Show summary statistics
df.describe(include='all')

# Display the first few rows again to check for structure
df.head()

# Check the data types of the columns
print(df.dtypes)

# Display unique values in each column to spot anomalies
for column in df.columns:
    print(f"Unique values in {column}: {df[column].unique()}")

import pandas as pd

# Load the CSV file, specifying that the first row is the header
file_path = '/content/IRIS.csv'
df = pd.read_csv(file_path, header=0)  # Use the first row as header

# Display the first few rows of the DataFrame
print("DataFrame after loading with headers:")
print(df.head())

# Convert numeric columns to the appropriate types
df['sepal_length'] = pd.to_numeric(df['sepal_length'], errors='coerce')
df['sepal_width'] = pd.to_numeric(df['sepal_width'], errors='coerce')
df['petal_length'] = pd.to_numeric(df['petal_length'], errors='coerce')
df['petal_width'] = pd.to_numeric(df['petal_width'], errors='coerce')

# Check for missing values after conversion
print("\nMissing values after type conversion:")
print(df.isnull().sum())

# Drop rows with any NaN values (if any)
#df = df.dropna()

# Display the cleaned DataFrame
print("\nCleaned DataFrame:")
print(df.head())

# Rename columns if needed
#df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']

# Verify column names
#print("\nColumn names after renaming (if needed):")
#print(df.columns)

# Save the cleaned DataFrame
cleaned_file_path = '/content/Cleaned_IRIS.xlsx'
df.to_excel(cleaned_file_path, index=False)

print(f"\nCleaned data saved to {cleaned_file_path}")

import pandas as pd

# Define the file path for the Excel file
excel_file_path = '/content/Cleaned_IRIS.xlsx'

# Load the Excel file into a DataFrame
df_from_excel = pd.read_excel(excel_file_path)

# Display the first few rows of the DataFrame
print("DataFrame loaded from Excel:")
print(df_from_excel.head())

# Load the original cleaned data from CSV
cleaned_csv_path = '/content/Cleaned_IRIS.csv'
df_cleaned = pd.read_csv(cleaned_csv_path)

# Verify if the data matches by checking for differences
data_mismatch = df_cleaned.compare(df_from_excel)
if data_mismatch.empty:
    print("The imported data matches the cleaned data.")
else:
    print("Differences found between the imported and cleaned data:")
    print(data_mismatch)

# Create a subset of the DataFrame
iris_subset = df_from_excel[['sepal_length', 'species']].head(10)  # Example: first 10 rows and specific columns

# Display the subset
print("Subset of the DataFrame:")
print(iris_subset)

# Define the file path for the JSON file
json_file_path = '/content/iris_subset.json'

# Save the subset to a JSON file
iris_subset.to_json(json_file_path, orient='records', lines=True)

print(f"The subset has been saved to {json_file_path}")