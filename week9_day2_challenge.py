# -*- coding: utf-8 -*-
"""Week9/day2/challenge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tUe_jYDGvGyvunpaPPdmfam6XFsaEJUn
"""

# Install Kaggle package and set up Kaggle API credentials
!pip install kaggle

# Upload your Kaggle API key file (kaggle.json)
from google.colab import files
files.upload()  # Choose the kaggle.json file that you downloaded from Kaggle

# Place the kaggle.json file in the correct location
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download the dataset from Kaggle
!kaggle datasets download harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows

# Unzip the downloaded file
import zipfile
import os

zip_path = '/content/imdb-dataset-of-top-1000-movies-and-tv-shows.zip'
extract_path = '/content/imdb_dataset'

os.makedirs(extract_path, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Import the dataset into a pandas DataFrame
import pandas as pd

file_path = os.path.join(extract_path, 'imdb_top_1000.csv')
imdb_df = pd.read_csv(file_path)

# Display the first few rows of the DataFrame
imdb_df.head()

# Check for missing values
print("\nMissing values in each column:")
print(imdb_df.isnull().sum())

# Handle missing values in 'Gross' and 'Meta_score' columns
imdb_df['Gross'].fillna(imdb_df['Gross'].median(), inplace=True)
imdb_df['Meta_score'].fillna(imdb_df['Meta_score'].median(), inplace=True)

# Verify missing values are handled
print("\nMissing values after handling:")
print(imdb_df.isnull().sum())

# Display data types of each column
print("\nData types of each column:")
print(imdb_df.dtypes)

# Convert 'Released_Year' to integer
imdb_df['Released_Year'] = imdb_df['Released_Year'].astype(int)

# Convert 'Gross' to float64
imdb_df['Gross'] = imdb_df['Gross'].astype('float64')

# Display the data types of each column
print("Data types of each column after conversion:")
print(imdb_df.dtypes)

# Display the amount of non-numeric values
non_numeric_released_year = imdb_df['Released_Year'].apply(lambda x: not str(x).isdigit()).sum()
non_numeric_gross = imdb_df['Gross'].apply(lambda x: not str(x).replace('$', '').replace(',', '').replace('.', '').isdigit()).sum()

print(f"\nAmount of non-numeric values in 'Released_Year': {non_numeric_released_year}")
print(f"Amount of non-numeric values in 'Gross': {non_numeric_gross}")

# Clean and convert 'Released_Year' to integer
# Remove non-numeric values
imdb_df['Released_Year'] = pd.to_numeric(imdb_df['Released_Year'], errors='coerce')

# Fill or drop NaN values if needed
imdb_df['Released_Year'].fillna(imdb_df['Released_Year'].median(), inplace=True)

# Convert to integer
imdb_df['Released_Year'] = imdb_df['Released_Year'].astype(int)

# Clean and convert 'Gross' to float64
# Remove non-numeric values
imdb_df['Gross'] = imdb_df['Gross'].replace('[\$,]', '', regex=True).astype(float)

# Fill or drop NaN values if needed
imdb_df['Gross'].fillna(imdb_df['Gross'].median(), inplace=True)

# Convert to float64
imdb_df['Gross'] = imdb_df['Gross'].astype('float64')

# Display the data types of each column
print("\nData types of each column after conversion:")
print(imdb_df.dtypes)

# Display the first few rows of the cleaned DataFrame
print("\nCleaned DataFrame:")
print(imdb_df.head())

# 3. Rating Trends Over Years
import matplotlib.pyplot as plt

# Group by Released_Year and calculate the mean IMDB_Rating for each year
rating_trends = imdb_df.groupby('Released_Year')['IMDB_Rating'].mean().reset_index()

# Plot the trends
plt.figure(figsize=(10, 6))
plt.plot(rating_trends['Released_Year'], rating_trends['IMDB_Rating'], marker='o')
plt.title('Trends in IMDB Rating Over the Years')
plt.xlabel('Year')
plt.ylabel('Average IMDB Rating')
plt.grid(True)
plt.show()

# 4. Genre Popularity Analysis

# List unique values in the 'Genre' column
unique_genres = imdb_df['Genre'].unique()

print("\nUnique values in 'Genre' column:")
print(unique_genres)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import drive

# Load the dataset from the provided file path
file_path = '/content/imdb_dataset/imdb_top_1000.csv'
imdb_df = pd.read_csv(file_path)

# Define the new categories based on the first word in the 'Genre' column
def map_genre(genre):
    first_word = genre.split(',')[0]
    if first_word in ['Action', 'Adventure']:
        return 'Action/Adventure'
    elif first_word == 'Drama':
        return 'Drama'
    elif first_word == 'Biography':
        return 'Biography'
    elif first_word == 'Comedy':
        return 'Comedy'
    elif first_word == 'Crime':
        return 'Crime'
    elif first_word == 'Animation':
        return 'Animation'
    elif first_word in ['Fantasy', 'Mystery']:
        return 'Fantasy/Mystery'
    elif first_word == 'Horror':
        return 'Horror'
    else:
        return 'Others'

imdb_df['New_Genre'] = imdb_df['Genre'].apply(map_genre)

# Count the number of movies in each new genre
genre_counts = imdb_df['New_Genre'].value_counts().reset_index()
genre_counts.columns = ['Genre', 'Count']

# Generate a Seaborn bar plot to compare the number of movies across different genres
plt.figure(figsize=(12, 6))
sns.barplot(data=genre_counts, x='Genre', y='Count', palette='viridis')
plt.title('Number of Movies Across Different Genres')
plt.xlabel('Genre')
plt.ylabel('Number of Movies')
plt.xticks(rotation=45)
plt.show()

# Extract the unique genres that fall under the 'Others' category
others_genres = imdb_df[imdb_df['New_Genre'] == 'Others']['Genre'].unique()

# Print the list of genres from the 'Others' category
print("Genres in the 'Others' category:")
for genre in others_genres:
    print(genre)

# 5.Directorâ€™s Impact on Ratings

unique_genres = imdb_df['Director'].unique()

print("\nUnique values in 'Director' column:")
print(unique_genres)

# Assamption: the greater the director's influence on the film's rating, the less the ratings of their films will differ
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import drive


# Load the dataset from the provided file path
file_path = '/content/imdb_dataset/imdb_top_1000.csv'
imdb_df = pd.read_csv(file_path)

# Filter directors with at least 2 movies
director_movie_counts = imdb_df['Director'].value_counts()
directors_with_multiple_movies = director_movie_counts[director_movie_counts >= 2].index
filtered_imdb_df = imdb_df[imdb_df['Director'].isin(directors_with_multiple_movies)]

# Calculate variance of ratings for the filtered directors
director_variance_ratings = filtered_imdb_df.groupby('Director')['IMDB_Rating'].var().reset_index()
director_variance_ratings.columns = ['Director', 'Variance_Rating']

# Select the top 50 directors with the lowest variance in ratings
top_50_lowest_variance_directors = director_variance_ratings.nsmallest(50, 'Variance_Rating')

# Create a scatter plot for the top 50 directors
plt.figure(figsize=(14, 8))
sns.scatterplot(data=top_50_lowest_variance_directors, x='Director', y='Variance_Rating', s=100, color='blue', alpha=0.7)

# Add labels and title
plt.xlabel('Director')
plt.ylabel('Variance of IMDB Rating')
plt.title('Top 50 Directors with Lowest Variance in IMDB Ratings (with at least 2 movies)')
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability

# Show plot
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import drive

# Mount Google Drive
#drive.mount('/content/drive')

# Load the dataset from the provided file path
file_path = '/content/imdb_dataset/imdb_top_1000.csv'
imdb_df = pd.read_csv(file_path)

# Filter directors with at least 2 movies
director_movie_counts = imdb_df['Director'].value_counts()
directors_with_multiple_movies = director_movie_counts[director_movie_counts >= 2].index
filtered_imdb_df = imdb_df[imdb_df['Director'].isin(directors_with_multiple_movies)]

# Calculate variance of ratings for the filtered directors
director_variance_ratings = filtered_imdb_df.groupby('Director')['IMDB_Rating'].var().reset_index()
director_variance_ratings.columns = ['Director', 'Variance_Rating']

# Select the top 20 directors with the lowest variance in ratings
top_20_lowest_variance_directors = director_variance_ratings.nsmallest(20, 'Variance_Rating')

# Calculate the number of movies and mean ratings for these directors
director_stats = filtered_imdb_df.groupby('Director').agg(
    Num_Movies=('IMDB_Rating', 'count'),
    Mean_Rating=('IMDB_Rating', 'mean')
).reset_index()

# Merge with the top 20 directors to get the required stats
top_20_director_stats = top_20_lowest_variance_directors.merge(director_stats, on='Director')

# Display the number of movies and their mean ratings for each of the top 20 directors
print(top_20_director_stats[['Director', 'Num_Movies', 'Mean_Rating', 'Variance_Rating']])

# 6. Star Power Analysis

import pandas as pd

file_path = '/content/imdb_dataset/imdb_top_1000.csv'
df = pd.read_csv(file_path)

# Correct the Gross column
df['Gross'] = df['Gross'].astype(str).str.replace(r'[$,M]', '', regex=True).str.replace('.', '', regex=False).astype(float)

# Melt the dataset to get a long format with each star's information
stars_df = df.melt(id_vars=['Series_Title', 'IMDB_Rating', 'Gross'], value_vars=['Star1', 'Star2', 'Star3', 'Star4'],
                   var_name='Star_Position', value_name='Star')

# Display the reshaped dataset
stars_df.head()

# Group by Star and calculate mean rating and total gross
star_stats = stars_df.groupby('Star').agg(
    mean_star_rating=('IMDB_Rating', 'mean'),
    total_star_gross=('Gross', 'sum')
).reset_index()

# Display the aggregated star statistics
star_stats.head()

# Merge star stats back into the original long format dataframe
merged_df = stars_df.merge(star_stats, on='Star', how='left')

# Pivot back to wide format to get mean rating and total gross for each movie
movie_stats = merged_df.pivot_table(index=['Series_Title', 'IMDB_Rating', 'Gross'],
                                    values=['mean_star_rating', 'total_star_gross'],
                                    aggfunc={'mean_star_rating': 'mean', 'total_star_gross': 'sum'}).reset_index()

# Display the merged dataset with aggregated star statistics
movie_stats.head()

import seaborn as sns
import matplotlib.pyplot as plt

# Plot the pairplot
sns.pairplot(movie_stats, vars=['IMDB_Rating', 'Gross', 'mean_star_rating', 'total_star_gross'])
plt.show()

# 7. Box Plot of Genres vs. Ratings

import pandas as pd

# Load the dataset
file_path = '/content/imdb_dataset/imdb_top_1000.csv'
df = pd.read_csv(file_path)

# Define the mapping function
def map_genre(genre):
    first_word = genre.split(',')[0]
    if first_word in ['Action', 'Adventure']:
        return 'Action/Adventure'
    elif first_word == 'Drama':
        return 'Drama'
    elif first_word == 'Biography':
        return 'Biography'
    elif first_word == 'Comedy':
        return 'Comedy'
    elif first_word == 'Crime':
        return 'Crime'
    elif first_word == 'Animation':
        return 'Animation'
    elif first_word in ['Fantasy', 'Mystery']:
        return 'Fantasy/Mystery'
    elif first_word == 'Horror':
        return 'Horror'
    else:
        return 'Others'

# Apply the mapping function to create a new Genre_Category column
df['Genre_Category'] = df['Genre'].apply(map_genre)

import seaborn as sns
import matplotlib.pyplot as plt

# Create the box plot
plt.figure(figsize=(12, 6))
sns.boxplot(x='Genre_Category', y='IMDB_Rating', data=df)
plt.xticks(rotation=45)
plt.title('Distribution of IMDB Ratings Across Genre Categories')
plt.xlabel('Genre Category')
plt.ylabel('IMDB Rating')
plt.show()

# 8. Correlation Heatmap

import pandas as pd

# Load the dataset
file_path = '/content/imdb_dataset/imdb_top_1000.csv'
df = pd.read_csv(file_path)

# Correct the Gross column
df['Gross'] = df['Gross'].astype(str).str.replace(r'[$,M]', '', regex=True).str.replace('.', '', regex=False).astype(float)

import seaborn as sns
import matplotlib.pyplot as plt

# Select the relevant columns
numerical_columns = ['IMDB_Rating', 'Meta_score', 'No_of_Votes', 'Gross']
df_numerical = df[numerical_columns]

# Calculate the correlation matrix
correlation_matrix = df_numerical.corr()

# Create a heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Heatmap of Numerical Columns')
plt.show()